\section{Related Work}
\label{sec_related_work}
Our work is related to document classification, which is a classic task in natural language processing (NLP). A simple but effective method is to combine bag-of-words (BOW) features with varies classifiers \cite{joachims1998text}. 
Recently, neural network (NN) models like Convolutional Neural Network (CNN) \cite{kim2014convolutional} have been used for document embedding, and the resultant document vecotr can be further passed to \orange{functions like softmax} for classification.
\cite{tang2015document} proposes a two-layer scheme, where they use recurrent neural network (RNN) or CNN for sentence embedding, and another RNN for document embedding. 
\cite{yang2016hierarchical} further utilizes attention mechanism by introducing a word-level and a sentence-level context vector to the two-layer scheme to distinguish informative words or sentences from non-informative ones. 
Our method shares similar spirit with \cite{yang2016hierarchical}, but we allow the context vectors to be dynamically generated for each datum when extra guidance is available.
Furthermore, our work also differs from these works in that we also extract relevant law articles, which are further used to support the charge classification. This require us to distinguish relevant articles from irrelevant ones, and further aggregate the information from two sources for classification.

As for multi-label document classification, two loss functions are commonly used. 
The first one is binary cross entropy \cite{nam2014large}, which treats the multi-label classification task as multiple binary classification tasks. 
The second one is cross entropy \cite{kurata2016improved}, which converts the multi-label target to label distribution during training, and use a threshold selected via validation set to generate the final prediction during testing. In our pilot experiments, we find the latter one converges faster and performs better, so we will use the latter one in this paper.

In the thread of work on predicting the outcome of a case, previous works mainly operate on a binary precition paradigm. 
Some aim at predicting wether the outcome will side with the plaintiff or defendant~\cite{bench1993neural,bruninghaus2003predicting,aletras2016predicting}, 
while others try to predict whether the justice or the present court will affirm or reverse the decision of a lower court \cite{martin2002dynamic,martin2004competing,lauderdale2014scaling,sim2015utility,katz2016general}\footnote{\cite{katz2016general} also use an additional \emph{other} class to handle the exception of other complex outcomes.}. 
Our work differs from them in two aspects. 
First, instead of general binary outcome, we step further to focuse on the detailed results of the case, i.e., the charges, where the output may contain multiple labels. 
Second, although \cite{aletras2016predicting} also tries to use relevant law articles for precition, we extract the articles by ourselves while they only use gold standard ones.

% Since the charges of the defendant are often part of the judgement result of a case, our task is also related to the thread of work on predicting the outcome of a case. Some work focuses on predicting wether the plaintiff will win or not \cite{aletras2016predicting}, while others try to predict whether the present court will affirm or reverse the decision of a lower court \cite{katz2016general}. The method can be domain specific logical model \cite{bruninghaus2003predicting}, multi-layer perceptron \cite{bench1993neural}, SVM \cite{aletras2016predicting} and random forest \cite{katz2016general}. Instead of predicting overall binary result, our task focuses on the detailed result of the case and our output may contain multiple charges. 

On the other hand, a recent work focuses specifically on finding relevant law articles based on the facts of a given case~\cite{liu2015predicting}.
They first use Support Vector Machine (SVM) for preliminary article classification, and then 
rerank the results by using the similarity between the words in fact description and law articles, and the correlations among law articles as indicators.
% use some reranking methods to get the final relevant article list. 
Our article modeling branch also utilizes SVM to extract top $k$ articles. However, to better understand the association between facts and articles, we use attention mechanism in NN to distinguish relevant ones in the top $k$ extraction results. \orange{To make our model fully differenciable,} rather than using frequent pattern mining techinque, we use RNN to model the correlations among articles.


Our work also shares similar spirit with the legal question answering task that, we all believe that relevant law articles are important for decisions in civil law system. This task is proposed by the Competition on Legal Information Extraction/Entailment (COLIEE) in 2014,
% \footnote{\url{http://webdocs.cs.ualberta.ca/~miyoung2/jurisin_task/index.html}}
and it aims at answering the yes/no questions in Japanese legal bar exams. The task first requires participants to extract relevant Japanese Civil Code articles, and then these articles are used to answer the yes/no question. 
The article extraction phase is often treated as an information retrieval task, and the question answering phase is usually considered as a textual entailment task~\cite{kim2014legal,kimconvolutional}
Another thread of work also tries to answer the multiple-choice questions in the USA National Bar Exam \cite{FAWEI16,adebayoneural}. Since the United States mainly operates on common law system, where statutory laws are less important, the relevant article extraction phase is not employed in these works.