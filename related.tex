\section{Related Work}
\label{sec_related_work}
Our work is closely related to document classification, which is a classic task in natural language processing (NLP). A simple but effective method is to combine bag-of-words (BOW) features with varies classifiers \cite{joachims1998text}. 
Recently, neural network (NN) models like Convolutional Neural Network (CNN) \cite{kim2014convolutional} have been used for document embedding, and the resultant document vecotr can be further passed to \orange{functions like softmax} for classification.
\cite{tang2015document} proposes a two-layer scheme, where they use recurrent neural network (RNN) or CNN for sentence embedding, and another RNN for document embedding. 
\cite{yang2016hierarchical} further utilizes attention mechanism by introducing a word-level and a sentence-level context vector to the two-layer scheme to distinguish informative words or sentences from non-informative ones. 
Our method shares similar spirit with \cite{yang2016hierarchical}, but we allow the context vectors to be dynamically generated for each datum when extra guidance is available. 
As for multi-label document classification, two loss functions are commonly used. 
The first one is binary cross entropy \cite{nam2014large}, which treats the multi-label classification task as multiple binary classification tasks. 
The second one is cross entropy \cite{kurata2016improved}, which converts the multi-label target to label distribution during training, and use a threshold selected via validation set to generate the final prediction during testing. In our pilot experiments, we find the latter one converges faster and performs better, so we will use the latter one in this paper.

Since the charges of the defendant are often part of the judgement result of a case, our task is also related to the thread of work on predicting the outcome of a case. Some work focuses on predicting wether the plaintiff will win or not \cite{bench1993neural,bruninghaus2003predicting,aletras2016predicting}, while others try to predict whether the present court will affirm or reverse the decision of a lower court \cite{martin2004competing,katz2016general}. Apart from case-level prediction, researches also try on predicting the votes of each justice \cite{martin2002dynamic,martin2004competing,lauderdale2014scaling,sim2015utility,katz2016general}. Our task differs from them in that we focuses on the detailed result of the case and our output may contain multiple charges.

% Since the charges of the defendant are often part of the judgement result of a case, our task is also related to the thread of work on predicting the outcome of a case. Some work focuses on predicting wether the plaintiff will win or not \cite{aletras2016predicting}, while others try to predict whether the present court will affirm or reverse the decision of a lower court \cite{katz2016general}. The method can be domain specific logical model \cite{bruninghaus2003predicting}, multi-layer perceptron \cite{bench1993neural}, SVM \cite{aletras2016predicting} and random forest \cite{katz2016general}. Instead of predicting overall binary result, our task focuses on the detailed result of the case and our output may contain multiple charges. 

Our work is also related to the work of \cite{liu2015predicting}, which aims at finding relevant law articles based on the facts of a given case. They proposes to first use Support Vector Machine (SVM) for preliminary article classification, and then 
rerank the results by using the similarity between the words in fact description and law articles, and the correlations among law articles as indicators.
% use some reranking methods to get the final relevant article list. 
Our article modeling branch also utilizes SVM to extract top $k$ articles, but we use the attention mechanism in neural network to resolve the noise in the top $k$ extraction results.

Our work also shares the same spirit with the legal question answering task that, we all believe that relevant law articles are important for decisions in civil law system. This task is proposed by the Competition on Legal Information Extraction/Entailment (COLIEE) in 2014,
% \footnote{\url{http://webdocs.cs.ualberta.ca/~miyoung2/jurisin_task/index.html}}
and it aims at answering the yes/no questions in Japanese legal bar exams. The task first requires participants to extract relevant Japanese Civil Code articles, and then these articles are used to answer the yes/no question. 
The article extraction phase is often treated as an information retrieval task, and the question answering phase is usually considered as a textual entailment task~\cite{kim2014legal,kimconvolutional}
Another thread of work also tries to answer the multiple-choice questions in the USA National Bar Exam \cite{FAWEI16,adebayoneural}. Since the United States mainly operates on common law system, where statutory laws are less important, the relevant article extraction phase is not employed in these works.